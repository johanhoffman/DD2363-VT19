{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-report-lab-X.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/tobzed/Lab-2/tedwards_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 2: Direct Methods**\n",
        "**Tobias Edwards**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This lab focussed on implementing the following:\n",
        "\n",
        "1. QR Factorization of matrix A\n",
        "2. A direct solver for Ax =b\n",
        "3. Least squares method for overdetermined systems\n",
        "4. QR eigenvalue algorithm\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**About the code**"
      ]
    },
    {
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code is written for Lab 2 in DD2363 Methods in Scientific Computing\n",
        "# Course given by the Royal Institute of Technology in Stockholm, KTH\n",
        "# Code by Tobias Edwards (tedwards@kth.se), Spring 2019"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These are the environment variables, make sure to run this code before trying any code below! "
      ]
    },
    {
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import unittest\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$QR$ factorization is used to represent matrices in such a way that is is easier to numerically calculate matrix inverses, for instance. $Q$ is a orthogonal matrix such that $Q^T$ = $Q^{-1}$.  Backward substitution is a iterative method used to solve the system $Rx = y$ where $R$ is an upper triangular matrix. Least squares method is a way to solve overdetermined systems that do not have exact solutions. In this case, a solution to an overdetermined system $Ax =b$, $A \\in R^{m\\times n}, x \\in R^{n}, b \\in R^{m}$, is $x$ such that $||Ax-b|| \\leq ||Ay-b||, \\forall y \\in R^n$.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ]
    },
    {
      "metadata": {
        "id": "HnnMjSZaH3fN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#QR factorization\n",
        "\n",
        "def gs(A):\n",
        "    #gram-schmidt method for creating a orthonormal matrix Q and upper triangular matrix R from A\n",
        "    rows,cols = A.shape\n",
        "    Q = np.zeros((rows,cols))\n",
        "    R = np.zeros((cols,cols))\n",
        "    for j in range(cols):\n",
        "        vj = A[:,j]\n",
        "        if j > 0: # if j == 0, we don't need to modify the direction of the corresponding vector\n",
        "            for i in range(j):\n",
        "                R[i,j] = np.inner(Q[:,i],A[:,j])\n",
        "                vj = np.subtract(vj,R[i,j]*Q[:,i])\n",
        "        R[j,j] = np.linalg.norm(vj)\n",
        "        Q[:,j] = vj/R[j,j]\n",
        "    return Q, R\n",
        "  \n",
        "A = np.array( [[1,2,0], [4,0,2], [100,0,1]] )\n",
        "Q,R = gs(A)\n",
        "print(\"Q = \", Q, \"R = \", R, \"A = \", A, \"QR = \", Q.dot(R), sep=\"\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AFBTTc4JT9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backward_substitution(R,b):\n",
        "    # R is an upper triangular matrix\n",
        "    x = np.zeros(b.shape)\n",
        "    n = R.shape[0]\n",
        "    x[n-1] = b[n-1] / R[n-1,n-1]\n",
        "    # iterate in reverse order to find x_i = b_i - sum(R_ij*x_j)/R_ii ,for j in [i+1,n)\n",
        "    for i in range(n-2,-1,-1):\n",
        "        x[i] = (b[i]-sum([R[i,j]*x[j] for j in range(i+1,n)]))/R[i,i]\n",
        "    return x\n",
        "  \n",
        "def direct_solver(A,b):\n",
        "    # Ax = b <=> QRx = b <=> Rx = Q^(⁻1)b = Q^(T)b\n",
        "    (Q,R) = gs(A)\n",
        "    # use backward backward_substitution to solve this \"new\" equation system\n",
        "    return backward_substitution(R,Q.transpose().dot(b))\n",
        "\n",
        "A = np.array( [[1,2,0], [4,0,2], [100,0,1]] )\n",
        "b = np.array( [3,-2,2] )\n",
        "x = direct_solver(A,b)\n",
        "print(\"A = \", A, \"b = \", b, \"x = \", x, sep=\"\\n\\n\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTzWxyjuJhtP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# least squares method\n",
        "\n",
        "def least_squares(A,b):\n",
        "    new_A = np.matmul(np.transpose(A),A)\n",
        "    # Ax = b is overdetermined\n",
        "    # normal equations: A^(T)Ax = A^(T)b\n",
        "    new_b = np.transpose(A).dot(b)\n",
        "    return direct_solver(new_A, new_b)\n",
        "\n",
        "A = np.array([[4,2], [-3,9], [22,1]])\n",
        "b = np.array([2,7,-1])\n",
        "x = least_squares(A,b)\n",
        "print(\"A = \", A, \"b = \", b, \"x = \", x, sep=\"\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XVVM0ZPJqQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this finds the largest eigenvalue lamda_1 and corresponding eigenvector v_1 for A\n",
        "def power_iteration(A):\n",
        "    v_1 = np.random.rand(A.shape[0])\n",
        "    v_1 *= 1/np.linalg.norm(v_1)\n",
        "    lamda_1 = 0\n",
        "    for k in range(100):\n",
        "        w = A.dot(v_1)\n",
        "        v_1 = w/np.linalg.norm(w)\n",
        "        lamda_1 = np.inner(v_1, A.dot(v_1))\n",
        "    return lamda_1, v_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qr34_YiELyK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ]
    },
    {
      "metadata": {
        "id": "xQtXsqfVL76q",
        "colab_type": "code",
        "outputId": "14a28d7b-23bc-4178-91c8-b398b19784f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        " # class for testing methods in lab 2 using unittest\n",
        "  \n",
        "class Lab2FunctionsTest(unittest.TestCase):\n",
        "\n",
        "    def test_qr_factorization(self):\n",
        "        # randomly generate a square matrix\n",
        "        A = np.random.rand(3,3)\n",
        "        Q,R = gs(A)\n",
        "        Qt = np.transpose(Q)\n",
        "        # tranpose(Q) = inverse(Q) -> tranpose(Q) * Q = I\n",
        "        # so Frobenius norm of : tranpose(Q) * Q - I = 0\n",
        "        self.assertTrue(np.linalg.norm(Qt.dot(Q)-np.identity(3)) < 0.000001)\n",
        "        # A = QR -> QR - A = 0-matrix -> Frobenius norm of QR-A = 0\n",
        "        self.assertTrue(np.linalg.norm(Q.dot(R)-A) < 0.000001)\n",
        "\n",
        "    def test_direct_solver(self):\n",
        "        A = np.random.rand(3,3)\n",
        "        b = np.random.rand(3)\n",
        "        x = direct_solver(A,b)\n",
        "        # if x is a solution to Ax = b, then Ax-b = 0\n",
        "        self.assertTrue(np.linalg.norm(A.dot(x)-b) < 0.0000001)\n",
        "\n",
        "        # pre calculated test\n",
        "        A2 = np.array([[1,2],[4,-2]])\n",
        "        y = np.array([1.4,0.8])\n",
        "        b2 = np.array([3,4])\n",
        "        x2 = direct_solver(A2,b2)\n",
        "        # assert that the numerical solution x2 is not far from the \"exact\" solution y2 |x-u| < eps\n",
        "        self.assertTrue(np.linalg.norm(x2-y) < 0.0000001)\n",
        "\n",
        "    def test_least_squares(self):\n",
        "        A = np.array([[1,2], [4,2], [-1,0]])\n",
        "        b = np.array([4,-2,3])\n",
        "        x = least_squares(A,b)\n",
        "        # x_np is numpy's least squares solution (np.linalg.lstsq)\n",
        "        x_np = np.linalg.lstsq(A,b,rcond=-1)[0]\n",
        "        self.assertTrue(np.linalg.norm(x-x_np) < 0.00000001)\n",
        "\n",
        "        # A test for a randomized overdetermined system\n",
        "        A_rand = np.random.rand(10,4)\n",
        "        b_rand = np.random.rand(10)\n",
        "        x_rand = least_squares(A_rand, b_rand)\n",
        "        x_np_rand = np.linalg.lstsq(A_rand,b_rand,rcond=-1)[0]\n",
        "        self.assertTrue(np.linalg.norm(x_rand-x_np_rand) < 0.00000001)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.034s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This lab was slightly more challening than the first lab. I could not figure out how to generate all Eigenvectors. Using the QR algorithm I was able to construct a similiar matrix to A that had A's Eigenvalues on its diagonal. But apart from the Eigenvalue problems the lab was good and interesting. "
      ]
    }
  ]
}