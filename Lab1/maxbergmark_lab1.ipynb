{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-report-lab-X.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/maxbergmark/Lab1/maxbergmark_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 1: Matrix algorithms**\n",
        "**Max Bergmark**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The objective in this lab is to implement algorithms for inner product, matrix-vector product, and matrix-matrix product. The bonus assignment involves designing a class for CRS representation of sparse matrices, and implementing matrix-vector multiplication using that class."
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**About the code**"
      ]
    },
    {
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I (Max Bergmark) is the author of the code in its entirety. Some help was taken from [StackOverflow](https://stackoverflow.com/) and from the [numpy documentation](https://docs.scipy.org/doc/)."
      ]
    },
    {
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab_type": "code",
        "outputId": "1707ad55-2a51-478f-b05f-8d2f4cb98f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2019 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To complete the assignments in this class, we will represent our data using numpy arrays. However, since the main task of this report is to imlpement algorithms for matrix multiplication, we will not use `np.dot`, which is numpy's own method for matrix multiplication.Aside from that, I haven't restricted usage of numpy methods for the assignments included in this report.\n",
        "\n",
        "One important distinction is that numpy does not store orientation for its 1D arrays. For this report, this implies that we will not make a distinction between $1\\times n$ vectors and $n\\times 1$ vectors. If such a discinction is neccesary, I would advice you to create the vectors as 2D matrices, where one of the dimensions has size 1. This will yield identical results. "
      ]
    },
    {
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Methods**"
      ]
    },
    {
      "metadata": {
        "id": "zF4iBj5VURZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Inner product\n",
        "\n",
        "The first task is to implement the inner product of two vectors. When the two vectors have equal length, the inner product is defined as $(x, y) = \\sum_i x_iy_i$, which is the sum of the elementwise product of both arrays. Fortunately, numpy provides us with simple syntax for implementing this efficiently.\n",
        "\n",
        "For all parts of this assignment, I will use `np.dot` as the reference, and assert that my own implementation yields identical results. I have designed the code as a test suite, where any error will throw an exception."
      ]
    },
    {
      "metadata": {
        "id": "crdlEI_unarV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product(x, y):\n",
        "\tif not (isinstance(x, np.ndarray) and isinstance(y, np.ndarray)):\n",
        "\t\traise TypeError(\"Both arguments must be numpy arrays\")\n",
        "\tif x.size != y.size:\n",
        "\t\traise ValueError(\"Vectors must be same length\")\n",
        "\treturn (x*y).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFa02UF-oQpf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Matrix-vector product\n",
        "\n",
        "The matrix-vector product is a bit more complicated, but we can extend our inner product to calculate it. In its essence, the matrix-vector product $Ax$is similar to calculating the inner product $(a_i, x)$ for each row $a_i$ in $A$. With the addition of a for loop, this is easily done, and works as expected."
      ]
    },
    {
      "metadata": {
        "id": "7kBZicSqo349",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product_matrix_vector(A, x):\n",
        "  if not (isinstance(A, np.ndarray) and isinstance(B, np.ndarray)):\n",
        "    raise TypeError(\"Both arguments must be numpy arrays\")\n",
        "  if A.shape[1] != x.size:\n",
        "    raise ValueError(\"Matrix dimensions are not compatible\")\n",
        "  \n",
        "  b = np.zeros((A.shape[0],))\n",
        "  for r in range(A.shape[0]):\n",
        "    b[r] = (A[r,:]*x).sum()\n",
        "  return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj6bLncvubet",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Matrix-matrix product\n",
        "\n",
        "To calculate matrix-matrix products, we can use the same logic as above, but with one more loop to iterate over the column vectors in the right multiplicand. I have extended the function above to handle both matrix-vector multiplication and matrix-matrix multiplication."
      ]
    },
    {
      "metadata": {
        "id": "IuHbjUczu4LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product_matrix(A, B):\n",
        "\tif not (isinstance(A, np.ndarray) and isinstance(B, np.ndarray)):\n",
        "\t\traise TypeError(\"Both arguments must be lists\")\n",
        "\n",
        "\tif B.ndim == 1:\n",
        "\t\tC = np.zeros((A.shape[0],))\n",
        "\t\tfor r in range(A.shape[0]):\n",
        "\t\t\tC[r] = (A[r,:]*B).sum()\n",
        "\telse:\n",
        "\t\tC = np.zeros((A.shape[0], B.shape[1]))\n",
        "\t\tfor c in range(B.shape[1]):\n",
        "\t\t\tfor r in range(A.shape[0]):\n",
        "\t\t\t\tC[r, c] = (A[r,:]*B[:,c]).sum()\n",
        "\treturn C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqNgJsaavrE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 1: CRS class\n",
        "\n",
        "The CRS class is a representation of a matrix using three vectors containing the non-zero elements, the column indices of said elements, and the indices of the previous two arrays where a new row starts. \n",
        "\n",
        "Due to some ambiguity in the specification of the format, I have concluded that in addition to this, we also need to store the dimensions of the original matrix."
      ]
    },
    {
      "metadata": {
        "id": "Z1bQfKiZwVai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8811a7d-433c-4608-c436-51b4cc64dd3e"
      },
      "cell_type": "code",
      "source": [
        "class CRS:\n",
        "\n",
        "\tdef __init__(self, A):\n",
        "\t\tself.one_indexed = False\n",
        "\t\tself.index_dtype = np.dtype(\"int64\")\n",
        "\t\tself.make_CRS(A)\n",
        "\n",
        "\tdef make_CRS(self, A):\n",
        "\t\tself.shape = A.shape\n",
        "\t\tself.dtype = A.dtype\n",
        "\t\tself.calc_val(A)\n",
        "\t\tself.calc_col_idx(A)\n",
        "\t\tself.calc_row_ptr(A)\n",
        "\t\t# self.make_one_indexed()\n",
        "\n",
        "\t@property\n",
        "\tdef val(self):\n",
        "\t\treturn self._val\n",
        "\t\n",
        "\t@property\n",
        "\tdef col_idx(self):\n",
        "\t\treturn self._col_idx + self.one_indexed\n",
        "\n",
        "\t@property\n",
        "\tdef row_ptr(self):\n",
        "\t\treturn self._row_ptr + self.one_indexed\n",
        "\n",
        "\tdef calc_val(self, A):\n",
        "\t\tself._val = A[A > 0].flatten()\n",
        "\n",
        "\tdef calc_col_idx(self, A):\n",
        "\t\t# generate matrix the same size as A, where a_ij = j\n",
        "\t\tcol_idx = np.tile(np.arange(A.shape[1]), (A.shape[0], 1))\n",
        "\t\tself._col_idx = col_idx[A > 0].flatten()\n",
        "\n",
        "\tdef calc_row_ptr(self, A):\n",
        "\t\t\"\"\"Calculates the values of the row_ptr array in the CRS\"\"\"\n",
        "\t\t# generate matrix the same size as A, where a_ij = i\n",
        "\t\trow_idx = np.tile(\n",
        "\t\t\tnp.arange(A.shape[0], dtype = self.index_dtype), \n",
        "\t\t\t(A.shape[1], 1)\n",
        "\t\t).T\n",
        "\t\t# extract the row indices where A is non-zero\n",
        "\t\trow_indices = row_idx[A > 0].flatten()\n",
        "\t\t# the differences of row_indices indicate where a new row begins\n",
        "\t\tdiffs = np.diff(row_indices)\n",
        "\t\t# to correctly handle empty rows, we must use this\n",
        "\t\treverse_bincount = np.repeat(np.arange(diffs.size), diffs)\n",
        "\t\trow_sums = A.sum(axis = 1)\n",
        "\t\trow_cumsum = row_sums.cumsum()\n",
        "\t\tempty_top_rows = (row_cumsum == 0).sum()\n",
        "\n",
        "\t\t# populate the row_ptr array\n",
        "\t\tself._row_ptr = np.zeros(self.shape[0], dtype = self.index_dtype)\n",
        "\t\tstart_index = empty_top_rows + 1\n",
        "\t\tend_index = reverse_bincount.size + 1 + empty_top_rows\n",
        "\t\tself._row_ptr[start_index:end_index] = reverse_bincount + 1\n",
        "\t\t# make sure that empty rows at the end are correctly reconstructed\n",
        "\t\tself._row_ptr[end_index:] = -1\n",
        "\t\t# self._row_ptr = np.array([0, 0, 3, -1])\n",
        "\n",
        "\tdef make_one_indexed(self):\n",
        "\t\t\"\"\"Transform col_idx and row_ptr to use 1-indexing in output, \n",
        "\t\tbut not in the internal state\"\"\"\n",
        "\t\tself.one_indexed = True\n",
        "\n",
        "\tdef print_stats(self):\n",
        "\t\tsize = (self._val.size * self.dtype.itemsize \n",
        "\t\t\t+ self._col_idx.size * self.index_dtype.itemsize\n",
        "\t\t\t+ self._row_ptr.size * self.index_dtype.itemsize)\n",
        "\t\toriginal_size = self.dtype.itemsize * self.shape[0] * self.shape[1]\n",
        "\t\tprint(\"Space needed: %d bytes\" % size)\n",
        "\t\tprint(\"Original matrix size: %d bytes\" % original_size)\n",
        "\t\tprint(\"Compression ratio: %.1f%%\" % (100*(1 - size / original_size),))\n",
        "\n",
        "\tdef reconstruct(self):\n",
        "\t\tA = np.zeros(self.shape, dtype = self.dtype)\n",
        "\t\trow_starts = np.zeros(self._val.size, dtype = self.index_dtype)\n",
        "\t\tbbins = np.bincount(self._row_ptr[self._row_ptr >= 0])\n",
        "\t\trow_starts[:bbins.size] += bbins\n",
        "\t\trow_idx = row_starts.cumsum() - 1\n",
        "\t\tA[row_idx, self._col_idx] = self.val\n",
        "\t\treturn A\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn str(self.reconstruct())\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\treturn self.reconstruct()\n",
        "\n",
        "\tdef __mul__(self, x):\n",
        "\t\treturn CRS.multiply(self, x)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef multiply_slow(A, B):\n",
        "\t\tif isinstance(A, CRS):\n",
        "\t\t\tA = A.reconstruct()\n",
        "\t\tif isinstance(B, CRS):\n",
        "\t\t\tB = B.reconstruct()\n",
        "\t\treturn np.dot(A, B)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef multiply(A, B):\n",
        "\t\tif isinstance(A, CRS):\n",
        "\t\t\trow_starts = np.zeros(A._val.size, dtype = np.int64)\n",
        "\t\t\tbbins = np.bincount(A._row_ptr[A._row_ptr >= 0])\n",
        "\t\t\trow_starts[:bbins.size] += bbins\n",
        "\t\t\trow_idx = row_starts.cumsum() - 1\n",
        "\t\t\tres = np.zeros(A.shape[0])\n",
        "\t\t\tscalar_product_pairs = B[A._col_idx] * A._val\n",
        "\t\t\tnp.add.at(res, row_idx, scalar_product_pairs)\n",
        "\t\t\treturn res\n",
        "\t\telif isinstance(B, CRS):\n",
        "\t\t\trow_starts = np.zeros(B._val.size, dtype = np.int64)\n",
        "\t\t\tbbins = np.bincount(B._row_ptr[B._row_ptr >= 0])\n",
        "\t\t\trow_starts[:bbins.size] += bbins\n",
        "\t\t\trow_idx = row_starts.cumsum() - 1\n",
        "\t\t\tres = np.zeros(B.shape[1])\n",
        "\t\t\tscalar_product_pairs = A[row_idx] * B._val\n",
        "\t\t\tnp.add.at(res, B._col_idx, scalar_product_pairs)\n",
        "\t\t\treturn res\n",
        "\n",
        "\t\treturn np.dot(A, B)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8FBNo7CwrD8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 2: CRS matrix-vector product\n",
        "\n",
        "To implement the matrix-vector product using the CRS format, we could simply ask the CRS class to reconstruct the matrix, and then use the reconstruction with our previous methods for multiplying matrices and vectors. However, we should use the fact that our matrix is sparse during the multiplication to improve performance.\n",
        "\n",
        "To see the implementation used, see the `multiply` method in the `CRS` class. It is not designed to handle matrix-matrix multiplication using CRS, but should work when one of the multiplicands is in CRS format, and the other one is a 1-dimensional numpy array of correct size."
      ]
    },
    {
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ]
    },
    {
      "metadata": {
        "id": "RLwlnOzuV-Cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Inner product"
      ]
    },
    {
      "metadata": {
        "id": "4KilLv5PywQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c62910ab-920a-4538-a375-c3904490bdb4"
      },
      "cell_type": "code",
      "source": [
        "def test_inner_product():\n",
        "\tx = np.random.rand(5)\n",
        "\ty = np.random.rand(5)\n",
        "\ttrue_value = np.dot(x, y)\n",
        "\tnp_test_value = inner_product(x, y)\n",
        "\tassert true_value == np_test_value\n",
        "  \n",
        "test_inner_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9lWT9ngIyyol",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Matrix-vector product"
      ]
    },
    {
      "metadata": {
        "id": "7DiCdm9Vy0-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ae368e1-b77c-4974-b01f-0ebe40229a78"
      },
      "cell_type": "code",
      "source": [
        "def test_matrix_vector_product():\n",
        "\tA = np.random.rand(5, 3)\n",
        "\tx = np.random.rand(3)\n",
        "\ttrue_value = np.dot(A, x)\n",
        "\tb = inner_product_matrix(A, x)\n",
        "\tassert np.allclose(true_value, b)\n",
        "\n",
        "test_matrix_vector_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pSE2kxGy7RQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Matrix-matrix product"
      ]
    },
    {
      "metadata": {
        "id": "tQ3Ncs01y-I-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d7eacb7-7a87-4443-f74b-16f6d2cf8596"
      },
      "cell_type": "code",
      "source": [
        "def test_matrix_matrix_product():\n",
        "\tA = np.random.rand(5, 3)\n",
        "\tB = np.random.rand(3, 4)\n",
        "\ttrue_value = np.dot(A, B)\n",
        "\tC = inner_product_matrix(A, B)\n",
        "\tassert np.allclose(true_value, C)\n",
        "\n",
        "test_matrix_matrix_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HLjsSTW5zQEa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 1: CRS class"
      ]
    },
    {
      "metadata": {
        "id": "Dj9HGQnzzUNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4291431a-8808-47cc-faee-255602556acd"
      },
      "cell_type": "code",
      "source": [
        "def test_known_CRS():\n",
        "\tsparse_matrix = np.array([\n",
        "\t [3, 2, 0, 2, 0, 0],\n",
        "\t [0, 2, 1, 0, 0, 0],\n",
        "\t [0, 0, 1, 0, 0, 0],\n",
        "\t [0, 0, 3, 2, 0, 0],\n",
        "\t [0, 0, 0, 0, 1, 0],\n",
        "\t [0, 0, 0, 0, 2, 3]])\n",
        "\n",
        "\tA_CRS = CRS(sparse_matrix)\n",
        "\tA_CRS.make_one_indexed()\n",
        "\t# A_CRS.print_stats()\n",
        "\tassert np.array_equal(A_CRS.val, [3, 2, 2, 2, 1, 1, 3, 2, 1, 2, 3])\n",
        "\tassert np.array_equal(A_CRS.col_idx, [1, 2, 4, 2, 3, 3, 3, 4, 5, 5, 6])\n",
        "\tassert np.array_equal(A_CRS.row_ptr, [1, 4, 6, 7, 9, 10])\n",
        "\tassert np.array_equal(A_CRS.reconstruct(), sparse_matrix)\n",
        "\n",
        "\n",
        "def test_large_CRS(m, n):\n",
        "\n",
        "\tsparse_matrix = np.zeros((m, n))\n",
        "\t# create a tridiagonal matrix with random integers\n",
        "\tnp.fill_diagonal(sparse_matrix, np.random.randint(0, 3, m))\n",
        "\tnp.fill_diagonal(sparse_matrix[:,1:], np.random.randint(0, 3, m-1))\n",
        "\tnp.fill_diagonal(sparse_matrix[1:,:], np.random.randint(0, 3, m-1))\n",
        "\n",
        "\tA_CRS = CRS(sparse_matrix)\n",
        "\n",
        "\t# assert that it can be properly reconstructed from its representation\n",
        "\tassert np.array_equal(A_CRS.reconstruct(), sparse_matrix)\n",
        "\n",
        "\n",
        "def test_CRS_matrix():\n",
        "\ttest_known_CRS()\n",
        "\tfor m in range(2, 50):\n",
        "\t\tfor n in range(2, 50):\n",
        "\t\t\ttest_large_CRS(m, n)\n",
        "      \n",
        "test_CRS_matrix()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IE8StouzWKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 2: CRS matrix-vector product"
      ]
    },
    {
      "metadata": {
        "id": "I_ZBAes-zl9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de1427c3-d222-450f-9488-3c315f900730"
      },
      "cell_type": "code",
      "source": [
        "def test_CRS_product_known():\n",
        "\tsparse_matrix = np.array([\n",
        "\t [3, 2, 0, 2, 0, 0],\n",
        "\t [0, 2, 1, 0, 0, 0],\n",
        "\t [0, 0, 1, 0, 0, 0],\n",
        "\t [0, 0, 3, 2, 0, 0],\n",
        "\t [0, 0, 0, 0, 1, 0],\n",
        "\t [0, 0, 0, 0, 2, 3]])\n",
        "\n",
        "\tA_CRS = CRS(sparse_matrix)\n",
        "\tt0 = time.clock()\n",
        "\ttrue_right_val = np.dot(sparse_matrix, [1, 2, 3, 4, 5, 6])\n",
        "\ttrue_left_val = np.dot([1, 2, 3, 4, 5, 6], sparse_matrix)\n",
        "\tt1 = time.clock()\n",
        "\tright_val = A_CRS * np.array([1, 2, 3, 4, 5, 6])\n",
        "\tleft_val = CRS.multiply(np.array([1, 2, 3, 4, 5, 6]), A_CRS)\n",
        "\tt2 = time.clock()\n",
        "\n",
        "\tassert np.array_equal(true_right_val, right_val)\n",
        "\tassert np.array_equal(true_left_val, left_val)\n",
        "\t# print((t1-t0)/(t2-t1))\n",
        "\n",
        "def test_CRS_product_large(m, n):\n",
        "\n",
        "\tsparse_matrix = np.zeros((m, n))\n",
        "\t# create a tridiagonal matrix with random integers\n",
        "\tnp.fill_diagonal(sparse_matrix, np.random.randint(0, 3, m))\n",
        "\tnp.fill_diagonal(sparse_matrix[:,1:], np.random.randint(0, 3, m-1))\n",
        "\tnp.fill_diagonal(sparse_matrix[1:,:], np.random.randint(0, 3, m-1))\n",
        "\n",
        "\tA_CRS = CRS(sparse_matrix)\n",
        "\tt0 = time.clock()\n",
        "\tleft_mult = np.random.rand(m)\n",
        "\tright_mult = np.random.rand(n)\n",
        "\ttrue_right_val = np.dot(sparse_matrix, right_mult)\n",
        "\ttrue_left_val = np.dot(left_mult, sparse_matrix)\n",
        "\tt1 = time.clock()\n",
        "\tright_val = A_CRS * right_mult\n",
        "\tleft_val = CRS.multiply(left_mult, A_CRS)\n",
        "\tt2 = time.clock()\n",
        "\n",
        "\t# print(true_right_val, right_val)\n",
        "\tassert np.allclose(true_right_val, right_val)\n",
        "\tassert np.allclose(true_left_val, left_val)\n",
        "\t# speedup = (t1-t0)/(t2-t1)\n",
        "\t# if speedup > 1:\n",
        "\t\t# print(\"%5dx%5d: %.2f\" % (m, n, speedup))\n",
        "\n",
        "def test_CRS_matrix_vector_product():\n",
        "  test_CRS_product_known()\n",
        "  array_dims = [2, 5, 10, 23, 50, 100, 200, 500, 1000]\n",
        "  for m in array_dims:\n",
        "    for n in array_dims:\n",
        "      test_CRS_product_large(m, n)\n",
        "\n",
        "test_CRS_matrix_vector_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKEjKvN4zwye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running all tests\n",
        "\n",
        "If you want to verify the entire test suite, you can run the cell below."
      ]
    },
    {
      "metadata": {
        "id": "kUekGXW1zy1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0de8d01b-55f7-479d-b21f-403466c3ed70"
      },
      "cell_type": "code",
      "source": [
        "def run_tests():\n",
        "\ttest_inner_product()\n",
        "\ttest_matrix_vector_product()\n",
        "\ttest_matrix_matrix_product()\n",
        "\ttest_CRS_matrix()\n",
        "\ttest_CRS_matrix_vector_product()\n",
        "\n",
        "run_tests()\n",
        "print(\"All tests passed!\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results are as expected. There is further room for improvement in the matrix-matrix product, as using a for loop is less efficient compared to using numpy methods. The CRS class also needed to store the dimensions of the matrix in addition to the three arrays described in the litterature. From some benchmarking, the CRS class was actually able to perform matrix-vector multiplication faster than numpy for very large matrices, which is very impressive. "
      ]
    }
  ]
}