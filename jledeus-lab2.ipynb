{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of template-report-lab-X.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/jledeus/jledeus-lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 2: Direct methods**\n",
        "**Johan LedÃ©us**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is labwork for DD2363"
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Mandatory assignment**"
      ]
    },
    {
      "metadata": {
        "id": "2AXTgK4lSoV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1. Function: QR factorization\n",
        "\n",
        "####Input: matrix A\n",
        "####Output: orthogonal matrix Q, upper triangular matrix R, such that A=QR\n",
        "####Test: R upper triangular, Frobenius norms $$|| Q^TQ-I ||_F, || QR-A ||_F$$"
      ]
    },
    {
      "metadata": {
        "id": "oeuM_3R-VDlt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Solution:\n",
        "Given matrix $A$ we want to find the orthogonal matrix $Q$ and the upper triangulat matrix $R$.\n",
        "\n",
        "1. Take the columns of $A$ and make it to an orthonormal set with Gram Schmidt. That will result in the orthogonal matrix $Q$. \n",
        "\n",
        "2. Since $Q$ is an orthonormal ($Q^{-1} = Q^T$) we know that $R = Q^T \\cdot A$\n",
        "\n",
        "#### Classical Gram-Schmidt orthogonalization (5.2)\n",
        "\n",
        "$$v_j = a_j - \\sum_{i=1}^{j-1}(a_j,q_i)q_i$$\n",
        "$$q_j = v_j/||v_j||$$ \n"
      ]
    },
    {
      "metadata": {
        "id": "W1qJ5r81VIJ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Code\n",
        "#### Dependencies\n",
        "import numpy as np\n",
        "\n",
        "# Gram schmidt\n",
        "def gram_schmidt(A):\n",
        "  Q = np.zeros(A.shape) # Result matrix with zero\n",
        "  # Sum part of equation above\n",
        "  for j in range(len(A)):\n",
        "    sum_part = np.zeros(np.size(A,1))\n",
        "    for i in range(j):\n",
        "      sum_part += np.dot(A[:,j],Q[:,i])*Q[:,i]\n",
        "    # Assign value and normalize the vector\n",
        "    Q[:,j] = A[:,j] - sum_part\n",
        "    Q[:,j] /= np.linalg.norm(Q[:,j])\n",
        "  return Q\n",
        "\n",
        "def qr_factorization(A):\n",
        "  Q = gram_schmidt(A)\n",
        "  R = np.matmul(np.transpose(Q),A)\n",
        "  return Q, R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zVEzfAvIlTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### For testing we make sure that R is an upper triangular matrix and compare the Frobenius norms $|| Q^TQ-I ||_F, || QR-A ||_F$\n",
        "\n",
        "$$||A||_F = \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^na_{ij}^2}$$ "
      ]
    },
    {
      "metadata": {
        "id": "Kxt_4p-gEpZS",
        "colab_type": "code",
        "outputId": "5de458d0-a74a-49fe-e39b-0cb232e755ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Upper triangular matrix test\n",
        "def upper_triangular_test(R):\n",
        "  for i in range(len(R)):\n",
        "    for j in range(i):\n",
        "      if R[i,j] > 0.00000000001: # Small epsilon value\n",
        "        return False\n",
        "  return True\n",
        "\n",
        "def frobenius_norms(M):\n",
        "  res = 0\n",
        "  for i in M:\n",
        "    for j in i:\n",
        "      res += j**2\n",
        "  return True if np.sqrt(res) < 0.00000000001 else False\n",
        "\n",
        "A = np.array([(1,1,0),(1,0,1),(0,1,1)])\n",
        "Q, R = qr_factorization(A)\n",
        "assert upper_triangular_test(R) == True\n",
        "assert frobenius_norms(np.matmul(np.transpose(Q),Q)-np.identity(len(Q))) == True\n",
        "assert frobenius_norms(np.matmul(Q,R)-A) == True\n",
        "print(\"Pass\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###2. Function: direct solver Ax=b\n",
        "\n",
        "####Input: matrix $A$, vector $b$\n",
        "####Output: vector $x=A^{-1}b$\n",
        "####Test: residual $|| Ax-b ||$, and $|| x-y ||$ where y is a manufactured solution with $b=Ay$"
      ]
    },
    {
      "metadata": {
        "id": "1SST6o7kh8rq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution\n",
        "Given that matrix **A** is non-singular, meaning that it's invertible,  we can indirectly compute its inverse. \n",
        "\n",
        "$$A = QR$$\n",
        "$$Ax=b \\iff  QRx=b \\iff Rx =Q^{-1}b=Q^{T}b$$\n",
        "The inverse of the orthogonal matrix **Q** is its transpose.\n",
        "Since **R** is an upper triangular matrix we can use the backward substitition (*Course litterature page 69*) \n"
      ]
    },
    {
      "metadata": {
        "id": "pVPIecxifjHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def direct_solver(A,b):\n",
        "  Q,R = qr_factorization(A)\n",
        "  b = np.transpose(Q).dot(b)\n",
        "  x = np.zeros(len(b))\n",
        "  \n",
        "  # Backward substitution \n",
        "  for i in range(len(b)-1, -1, -1):\n",
        "    x[i] = (b[i]-sum([R[i][j]*x[j] for j in range(i+1,len(b))]))/R[i][i]\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NW59XherGFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "772264f6-e321-411e-8f29-b76606bfde28"
      },
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "A = np.array([(1,1,1),(0,2,5),(2,5,-1)])\n",
        "b = np.array([6,-4,27])\n",
        "x = direct_solver(A,b)\n",
        "y = np.linalg.inv(A).dot(b) # Manufactured solution\n",
        "\n",
        "assert np.linalg.norm(A.dot(x) - b) < 0.0000000001\n",
        "assert np.linalg.norm(x-y) < 0.0000000001\n",
        "print(\"Pass\")\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Extra assignment**"
      ]
    },
    {
      "metadata": {
        "id": "v6GRME6-UEpt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3. Function: least squares problem $Ax=b$\n",
        "\n",
        "####Input: matrix $A$, vector $b$\n",
        "####Output: vector $x$ \n",
        "####Test: residual $|| Ax-b ||$"
      ]
    },
    {
      "metadata": {
        "id": "1wJenxT70ZZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution (5.4 in course litterature)\n",
        "If the system is overdetermined and there exists no precise solution we want to find $x \\in \\Bbb R^n $ that minimize $r = b-Ax$, so that\n",
        "\n",
        "$$||b-Ax|| \\leq ||b-Ay||, \\forall y \\in \\Bbb R^n $$\n",
        "\n",
        "Given this we want to calculate the projected vector $Ax$ which is perpendicular to $r=b-Ax$. Since it's perpendicular to $range(A) \\implies A^Tr = 0 $.\n",
        "\n",
        "$$A^TAx = A^Tb-A^Tr = A^Tb \\implies x=(A^TA)^{-1}A^Tb $$"
      ]
    },
    {
      "metadata": {
        "id": "MI4Qt-Zb0cFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def least_squares(A,b):\n",
        "  b = np.transpose(A).dot(b) # A^Tb\n",
        "  A = np.matmul(np.transpose(A),A) # A^TA\n",
        "  return direct_solver(A,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owqSJHDFnkOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d702846e-f448-4451-b0ee-025e1678faa9"
      },
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "A = np.array([(1,-1),(1,1),(2,1)])\n",
        "b = np.array([2,4,8])\n",
        "x = least_squares(A,b)\n",
        "y = np.linalg.lstsq(A,b, rcond=-1)[0] # Manufactured solution\n",
        "\n",
        "# compare with library solution\n",
        "assert np.abs(np.linalg.norm(A.dot(x) - b) - np.linalg.norm(A.dot(y) - b)) < 0.00000001\n",
        "# Extra test, the dot product of r and Ax should be 0\n",
        "assert (b-A.dot(x)).dot(A.dot(x)) < 0.00000000001\n",
        "\n",
        "print(\"Pass\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cXG3dhdJUcSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###4. Function: QR eigenvalue algorithm\n",
        "\n",
        "####Input: real symmetric matrix $A$\n",
        "####Output: real eigenvalues $\\lambda_i$ and real eigenvectors $v_i$ of $A$\n",
        "####Test: $det(A - \\lambda_i I), || Av_i - \\lambda_i v_i ||$  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BNrTls63AWgO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution (6.2 in course litterature)\n",
        "With the QR eigenvalue algorithm the input matrix $A$ will converge to an upper triangular matrix. One property of an upper triangular matrix is that the diagonal values are in fact the eigenvalues.\n",
        "\n",
        "We can find the eigenvectors in the columns of: $\\prod_iQ_i$\n",
        "\n",
        "[External resources](https://people.kth.se/~eliasj/qrmethod.pdf)"
      ]
    },
    {
      "metadata": {
        "id": "TtM3RigiAYNA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def qr_eigenvalue_algorithm(A):\n",
        "  eigenvectors = np.identity(len(A[0]))\n",
        "  while not upper_triangular_teset(A):\n",
        "    Q,R = qr_factorization(A)\n",
        "    A = np.matmul(R,Q)\n",
        "    eigenvectors = np.matmul(eigenvectors, Q)\n",
        "  return A.diagonal(), np.transpose(eigenvectors)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeKAL9UEj9rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4727b633-26c6-47de-b5cd-1585f53cd650"
      },
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "\n",
        "A = np.array([(2,1,-3),(1,0,4),(-3,4,-1)])\n",
        "eigenvalues, eigenvectors = qr_eigenvalue_algorithm(A)\n",
        "\n",
        "for eigen in eigenvalues:\n",
        "  assert np.linalg.det(A - eigen*np.identity(len(A))) < 0.00000001\n",
        "  \n",
        "for i in range(len(eigenvectors)):\n",
        "  assert np.linalg.norm(np.abs(A.dot(eigenvectors[i]) - eigenvalues[i]*eigenvectors[i])) < 0.00000001\n",
        "print(\"pass\")"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Db3g4X-UwxsJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ]
    },
    {
      "metadata": {
        "id": "n1xi6UWjw0j_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This lab was more challenging than the previous one. But at the same time it was fun to repeat some old linear algebra. The hardest part was to construct the eigenvectors in assignment 4 since it wasn't that intuitive."
      ]
    }
  ]
}