{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maxbergmark_lab1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/maxbergmark/Lab-1/maxbergmark_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 1: Matrix algorithms**\n",
        "**Max Bergmark**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The objective in this lab is to implement algorithms for inner product, matrix-vector product, and matrix-matrix product. The bonus assignment involves designing a class for CRS representation of sparse matrices, and implementing matrix-vector multiplication using that class."
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**About the code**"
      ]
    },
    {
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I (Max Bergmark) is the author of the code in its entirety. Some help was taken from [StackOverflow](https://stackoverflow.com/) and from the [numpy documentation](https://docs.scipy.org/doc/)."
      ]
    },
    {
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To complete the assignments in this class, we will represent our data using numpy arrays. However, since the main task of this report is to imlpement algorithms for matrix multiplication, we will not use `np.dot`, which is numpy's own method for matrix multiplication.Aside from that, I haven't restricted usage of numpy methods for the assignments included in this report.\n",
        "\n",
        "One important distinction is that numpy does not store orientation for its 1D arrays. For this report, this implies that we will not make a distinction between $1\\times n$ vectors and $n\\times 1$ vectors. If such a discinction is neccesary, I would advice you to create the vectors as 2D matrices, where one of the dimensions has size 1. This will yield identical results. "
      ]
    },
    {
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Methods**\n",
        "\n",
        "Here I describe all the functions implemented for this laboration. To test all the parts of the lab, all code snippets in this document should be run **in order**. "
      ]
    },
    {
      "metadata": {
        "id": "zF4iBj5VURZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Inner product\n",
        "\n",
        "The first task is to implement the inner product of two vectors. When the two vectors have equal length, the inner product is defined as $(x, y) = \\sum_i x_iy_i$, which is the sum of the elementwise product of both arrays. Fortunately, numpy provides us with simple syntax for implementing this efficiently.\n",
        "\n",
        "For all parts of this assignment, I will use `np.dot` as the reference, and assert that my own implementation yields identical results. I have designed the code as a test suite, where any error will throw an exception."
      ]
    },
    {
      "metadata": {
        "id": "crdlEI_unarV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product(x, y):\n",
        "    if not (isinstance(x, np.ndarray) and isinstance(y, np.ndarray)):\n",
        "        raise TypeError(\"Both arguments must be numpy arrays\")\n",
        "    if x.size != y.size:\n",
        "        raise ValueError(\"Vectors must be same length\")\n",
        "    return (x*y).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFa02UF-oQpf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Matrix-vector product\n",
        "\n",
        "The matrix-vector product is a bit more complicated, but we can extend our inner product to calculate it. In its essence, the matrix-vector product $Ax$is similar to calculating the inner product $(a_i, x)$ for each row $a_i$ in $A$. With the addition of a for loop, this is easily done, and works as expected."
      ]
    },
    {
      "metadata": {
        "id": "7kBZicSqo349",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product_matrix_vector(A, x):\n",
        "    if not (isinstance(A, np.ndarray) and isinstance(B, np.ndarray)):\n",
        "        raise TypeError(\"Both arguments must be numpy arrays\")\n",
        "    if A.shape[1] != x.size:\n",
        "        raise ValueError(\"Matrix dimensions are not compatible\")\n",
        "  \n",
        "    b = np.zeros((A.shape[0],))\n",
        "    for r in range(A.shape[0]):\n",
        "        b[r] = (A[r,:]*x).sum()\n",
        "    return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj6bLncvubet",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Matrix-matrix product\n",
        "\n",
        "To calculate matrix-matrix products, we can use the same logic as above, but with one more loop to iterate over the column vectors in the right multiplicand. I have extended the function above to handle both matrix-vector multiplication and matrix-matrix multiplication."
      ]
    },
    {
      "metadata": {
        "id": "IuHbjUczu4LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inner_product_matrix(A, B):\n",
        "    if not (isinstance(A, np.ndarray) and isinstance(B, np.ndarray)):\n",
        "        raise TypeError(\"Both arguments must be lists\")\n",
        "\n",
        "    if B.ndim == 1:\n",
        "        C = np.zeros((A.shape[0],))\n",
        "        for r in range(A.shape[0]):\n",
        "            C[r] = (A[r,:]*B).sum()\n",
        "    else:\n",
        "        C = np.zeros((A.shape[0], B.shape[1]))\n",
        "        for c in range(B.shape[1]):\n",
        "            for r in range(A.shape[0]):\n",
        "                C[r, c] = (A[r,:]*B[:,c]).sum()\n",
        "    return C\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqNgJsaavrE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 1: CRS class\n",
        "\n",
        "The CRS class is a representation of a matrix using three vectors containing the non-zero elements, the column indices of said elements, and the indices of the previous two arrays where a new row starts and ends.\n",
        "\n",
        "In order to generate the CRS representation efficiently, I have resorted to using multiple numpy functions for increased performance. Python code is generally a lot slower than numpy, which is why for loops should be avoided if possible. "
      ]
    },
    {
      "metadata": {
        "id": "Z1bQfKiZwVai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CRS:\n",
        "\n",
        "    def __init__(self, A):\n",
        "        self.one_indexed = False\n",
        "        self.index_dtype = np.dtype(\"int64\")\n",
        "        self.make_CRS(A)\n",
        "\n",
        "    def make_CRS(self, A):\n",
        "        self.shape = A.shape\n",
        "        self.dtype = A.dtype\n",
        "        self.calc_val(A)\n",
        "        self.calc_col_idx(A)\n",
        "        self.calc_row_ptr(A)\n",
        "\n",
        "    @property\n",
        "    def val(self):\n",
        "        return self._val\n",
        "    \n",
        "    @property\n",
        "    def col_idx(self):\n",
        "        return self._col_idx + self.one_indexed\n",
        "\n",
        "    @property\n",
        "    def row_ptr(self):\n",
        "        return self._row_ptr + self.one_indexed\n",
        "\n",
        "    def calc_val(self, A):\n",
        "        self._val = A[A > 0].flatten()\n",
        "\n",
        "    def calc_col_idx(self, A):\n",
        "        # generate matrix the same size as A, where a_ij = j\n",
        "        col_idx = np.tile(np.arange(A.shape[1]), (A.shape[0], 1))\n",
        "        self._col_idx = col_idx[A > 0].flatten()\n",
        "\n",
        "    def calc_row_ptr(self, A):\n",
        "        \"\"\"Calculates the values of the row_ptr array in the CRS\"\"\"\n",
        "        # generate matrix the same size as A, where a_ij = i\n",
        "        row_idx = np.tile(\n",
        "            np.arange(A.shape[0], dtype = self.index_dtype), \n",
        "            (A.shape[1], 1)\n",
        "        ).T\n",
        "        # extract the row indices where A is non-zero\n",
        "        row_indices = row_idx[A > 0].flatten()\n",
        "        # the differences of row_indices indicate where a new row begins\n",
        "        diffs = np.diff(row_indices)\n",
        "        # to correctly handle empty rows, we must use this\n",
        "        reverse_bincount = np.repeat(np.arange(diffs.size), diffs)\n",
        "        row_sums = A.sum(axis = 1)\n",
        "        row_cumsum = row_sums.cumsum()\n",
        "        # this will give us the number of empty rows at the top of the matrix\n",
        "        empty_top_rows = (row_cumsum == 0).sum()\n",
        "\n",
        "        # populate the row_ptr array\n",
        "        self._row_ptr = np.zeros(self.shape[0] + 1, dtype = self.index_dtype)\n",
        "        # start populating the row_ptr array after the empty rows are handled\n",
        "        start_index = empty_top_rows + 1\n",
        "        end_index = reverse_bincount.size + 1 + empty_top_rows\n",
        "        self._row_ptr[start_index:end_index] = reverse_bincount + 1\n",
        "        # make sure that empty rows at the end are correctly reconstructed\n",
        "        self._row_ptr[end_index:] = self._val.size\n",
        "        # self._row_ptr[-1] = self._val.size\n",
        "\n",
        "    def make_one_indexed(self):\n",
        "        \"\"\"Transform col_idx and row_ptr to use 1-indexing in output, \n",
        "        but not in the internal state\"\"\"\n",
        "        self.one_indexed = True\n",
        "\n",
        "    def print_stats(self):\n",
        "        \"\"\"Prints stats regarding compression ratio and space used for CRS\"\"\"\n",
        "        size = (self._val.size * self.dtype.itemsize \n",
        "            + self._col_idx.size * self.index_dtype.itemsize\n",
        "            + self._row_ptr.size * self.index_dtype.itemsize)\n",
        "        original_size = self.dtype.itemsize * self.shape[0] * self.shape[1]\n",
        "        print(\"Space needed: %d bytes\" % size)\n",
        "        print(\"Original matrix size: %d bytes\" % original_size)\n",
        "        print(\"Compression ratio: %.1f%%\" % (100*(1 - size / original_size),))\n",
        "\n",
        "    def reconstruct(self):\n",
        "        \"\"\"Reconstructs A from its CRS representation\"\"\"\n",
        "        A = np.zeros(self.shape, dtype = self.dtype)\n",
        "        row_starts = np.zeros(self._val.size, dtype = self.index_dtype)\n",
        "        bbins = np.bincount(self._row_ptr[self._row_ptr < self._val.size])\n",
        "        row_starts[:bbins.size] += bbins\n",
        "        row_idx = row_starts.cumsum() - 1\n",
        "        A[row_idx, self._col_idx] = self.val\n",
        "        return A\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.reconstruct())\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.reconstruct()\n",
        "\n",
        "    def __mul__(self, x):\n",
        "        return CRS.multiply(self, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def multiply_slow(A, B):\n",
        "        if isinstance(A, CRS):\n",
        "            A = A.reconstruct()\n",
        "        if isinstance(B, CRS):\n",
        "            B = B.reconstruct()\n",
        "        return np.dot(A, B)\n",
        "\n",
        "    @staticmethod\n",
        "    def multiply(A, B):\n",
        "        if isinstance(A, CRS):\n",
        "            row_starts = np.zeros(A._val.size, dtype = np.int64)\n",
        "            bbins = np.bincount(A._row_ptr[A._row_ptr < A._val.size])\n",
        "            row_starts[:bbins.size] += bbins\n",
        "            row_idx = row_starts.cumsum() - 1\n",
        "            res = np.zeros(A.shape[0])\n",
        "            scalar_product_pairs = B[A._col_idx] * A._val\n",
        "            np.add.at(res, row_idx, scalar_product_pairs)\n",
        "            return res\n",
        "        elif isinstance(B, CRS):\n",
        "            row_starts = np.zeros(B._val.size, dtype = np.int64)\n",
        "            bbins = np.bincount(B._row_ptr[B._row_ptr < B._val.size])\n",
        "            row_starts[:bbins.size] += bbins\n",
        "            row_idx = row_starts.cumsum() - 1\n",
        "            res = np.zeros(B.shape[1])\n",
        "            scalar_product_pairs = A[row_idx] * B._val\n",
        "            np.add.at(res, B._col_idx, scalar_product_pairs)\n",
        "            return res\n",
        "\n",
        "        return np.dot(A, B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8FBNo7CwrD8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 2: CRS matrix-vector product\n",
        "\n",
        "To implement the matrix-vector product using the CRS format, we could simply ask the CRS class to reconstruct the matrix, and then use the reconstruction with our previous methods for multiplying matrices and vectors. However, we should use the fact that our matrix is sparse during the multiplication to improve performance.\n",
        "\n",
        "To see the implementation used, see the `multiply` method in the `CRS` class. It is not designed to handle matrix-matrix multiplication using CRS, but should work when one of the multiplicands is in CRS format, and the other one is a 1-dimensional numpy array of correct size.\n",
        "\n",
        "To get the matrix-vector multiplication working efficiently, I resorted to calculating an analogous counterpart to `col_idx` called `row_idx`. If I was to implement the algorithm in C/C++, I'd use loops directly. However, it is usually much faster to use numpy operations in Python, as they themselves are implemented in C. That is the main reason why I have avoided any looping in the CRS class. "
      ]
    },
    {
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ]
    },
    {
      "metadata": {
        "id": "RLwlnOzuV-Cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Inner product"
      ]
    },
    {
      "metadata": {
        "id": "4KilLv5PywQ1",
        "colab_type": "code",
        "outputId": "3422d6ab-1af5-4784-f130-8340c8058881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_inner_product():\n",
        "    x = np.random.rand(5)\n",
        "    y = np.random.rand(5)\n",
        "    true_value = np.dot(x, y)\n",
        "    np_test_value = inner_product(x, y)\n",
        "    assert true_value == np_test_value\n",
        "  \n",
        "test_inner_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9lWT9ngIyyol",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Matrix-vector product"
      ]
    },
    {
      "metadata": {
        "id": "7DiCdm9Vy0-X",
        "colab_type": "code",
        "outputId": "00bd25dd-0e27-478c-bca8-b2b90b1f6a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_matrix_vector_product():\n",
        "    A = np.random.rand(5, 3)\n",
        "    x = np.random.rand(3)\n",
        "    true_value = np.dot(A, x)\n",
        "    b = inner_product_matrix(A, x)\n",
        "    assert np.allclose(true_value, b)\n",
        "\n",
        "test_matrix_vector_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pSE2kxGy7RQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Matrix-matrix product"
      ]
    },
    {
      "metadata": {
        "id": "tQ3Ncs01y-I-",
        "colab_type": "code",
        "outputId": "46493361-4603-487f-ada7-774e75e06ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_matrix_matrix_product():\n",
        "    A = np.random.rand(5, 3)\n",
        "    B = np.random.rand(3, 4)\n",
        "    true_value = np.dot(A, B)\n",
        "    C = inner_product_matrix(A, B)\n",
        "    assert np.allclose(true_value, C)\n",
        "\n",
        "test_matrix_matrix_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HLjsSTW5zQEa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 1: CRS class"
      ]
    },
    {
      "metadata": {
        "id": "Dj9HGQnzzUNS",
        "colab_type": "code",
        "outputId": "274660d4-8cd6-4d60-9b4c-d776fff4bac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_known_CRS():\n",
        "    sparse_matrix = np.array([\n",
        "     [3, 2, 0, 2, 0, 0],\n",
        "     [0, 2, 1, 0, 0, 0],\n",
        "     [0, 0, 1, 0, 0, 0],\n",
        "     [0, 0, 3, 2, 0, 0],\n",
        "     [0, 0, 0, 0, 1, 0],\n",
        "     [0, 0, 0, 0, 2, 3]])\n",
        "\n",
        "    A_CRS = CRS(sparse_matrix)\n",
        "    A_CRS.make_one_indexed()\n",
        "    # A_CRS.print_stats()\n",
        "    assert np.array_equal(A_CRS.val, [3, 2, 2, 2, 1, 1, 3, 2, 1, 2, 3])\n",
        "    assert np.array_equal(A_CRS.col_idx, [1, 2, 4, 2, 3, 3, 3, 4, 5, 5, 6])\n",
        "    assert np.array_equal(A_CRS.row_ptr, [1, 4, 6, 7, 9, 10, 12])\n",
        "    assert np.array_equal(A_CRS.reconstruct(), sparse_matrix)\n",
        "\n",
        "\n",
        "def test_large_CRS(m, n):\n",
        "\n",
        "    sparse_matrix = np.zeros((m, n))\n",
        "    # create a tridiagonal matrix with random integers\n",
        "    np.fill_diagonal(sparse_matrix, np.random.randint(0, 3, m))\n",
        "    np.fill_diagonal(sparse_matrix[:,1:], np.random.randint(0, 3, m-1))\n",
        "    np.fill_diagonal(sparse_matrix[1:,:], np.random.randint(0, 3, m-1))\n",
        "\n",
        "    A_CRS = CRS(sparse_matrix)\n",
        "\n",
        "    # assert that it can be properly reconstructed from its representation\n",
        "    assert np.array_equal(A_CRS.reconstruct(), sparse_matrix)\n",
        "\n",
        "\n",
        "def test_CRS_matrix():\n",
        "    test_known_CRS()\n",
        "    for m in range(2, 50):\n",
        "        for n in range(2, 50):\n",
        "            test_large_CRS(m, n)\n",
        "            \n",
        "test_CRS_matrix()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IE8StouzWKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bonus 2: CRS matrix-vector product"
      ]
    },
    {
      "metadata": {
        "id": "I_ZBAes-zl9y",
        "colab_type": "code",
        "outputId": "cdf7f5f6-a20a-4bba-caaa-a7a259605e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_CRS_product_known():\n",
        "    sparse_matrix = np.array([\n",
        "     [3, 2, 0, 2, 0, 0],\n",
        "     [0, 2, 1, 0, 0, 0],\n",
        "     [0, 0, 1, 0, 0, 0],\n",
        "     [0, 0, 3, 2, 0, 0],\n",
        "     [0, 0, 0, 0, 1, 0],\n",
        "     [0, 0, 0, 0, 2, 3]])\n",
        "\n",
        "    A_CRS = CRS(sparse_matrix)\n",
        "    t0 = time.clock()\n",
        "    true_right_val = np.dot(sparse_matrix, [1, 2, 3, 4, 5, 6])\n",
        "    true_left_val = np.dot([1, 2, 3, 4, 5, 6], sparse_matrix)\n",
        "    t1 = time.clock()\n",
        "    right_val = A_CRS * np.array([1, 2, 3, 4, 5, 6])\n",
        "    left_val = CRS.multiply(np.array([1, 2, 3, 4, 5, 6]), A_CRS)\n",
        "    t2 = time.clock()\n",
        "\n",
        "    assert np.array_equal(true_right_val, right_val)\n",
        "    assert np.array_equal(true_left_val, left_val)\n",
        "    # print((t1-t0)/(t2-t1))\n",
        "\n",
        "def test_CRS_product_large(m, n):\n",
        "\n",
        "    sparse_matrix = np.zeros((m, n))\n",
        "    # create a tridiagonal matrix with random integers\n",
        "    np.fill_diagonal(sparse_matrix, np.random.randint(0, 3, m))\n",
        "    np.fill_diagonal(sparse_matrix[:,1:], np.random.randint(0, 3, m-1))\n",
        "    np.fill_diagonal(sparse_matrix[1:,:], np.random.randint(0, 3, m-1))\n",
        "\n",
        "    A_CRS = CRS(sparse_matrix)\n",
        "    t0 = time.clock()\n",
        "    left_mult = np.random.rand(m)\n",
        "    right_mult = np.random.rand(n)\n",
        "    true_right_val = np.dot(sparse_matrix, right_mult)\n",
        "    true_left_val = np.dot(left_mult, sparse_matrix)\n",
        "    t1 = time.clock()\n",
        "    right_val = A_CRS * right_mult\n",
        "    left_val = CRS.multiply(left_mult, A_CRS)\n",
        "    t2 = time.clock()\n",
        "\n",
        "    # print(true_right_val, right_val)\n",
        "    assert np.allclose(true_right_val, right_val)\n",
        "    assert np.allclose(true_left_val, left_val)\n",
        "    # speedup = (t1-t0)/(t2-t1)\n",
        "    # if speedup > 1:\n",
        "        # print(\"%5dx%5d: %.2f\" % (m, n, speedup))\n",
        "\n",
        "def test_CRS_matrix_vector_product():\n",
        "    test_CRS_product_known()\n",
        "    array_dims = [2, 5, 10, 23, 50, 100, 200, 500, 1000]\n",
        "    for m in array_dims:\n",
        "        for n in array_dims:\n",
        "            test_CRS_product_large(m, n)\n",
        "            \n",
        "test_CRS_matrix_vector_product()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKEjKvN4zwye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running all tests\n",
        "\n",
        "If you want to verify the entire test suite, you can run the cell below."
      ]
    },
    {
      "metadata": {
        "id": "kUekGXW1zy1W",
        "colab_type": "code",
        "outputId": "9cef74d9-ec15-4f5b-a430-4f80ecfe3a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def run_tests():\n",
        "    test_inner_product()\n",
        "    test_matrix_vector_product()\n",
        "    test_matrix_matrix_product()\n",
        "    test_CRS_matrix()\n",
        "    test_CRS_matrix_vector_product()\n",
        "\n",
        "run_tests()\n",
        "print(\"All tests passed!\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results are as expected. There is further room for improvement in the matrix-matrix product, as using a for loop is less efficient compared to using numpy methods. The CRS class also needed to store the dimensions of the matrix in addition to the three arrays described in the litterature. From some benchmarking, the CRS class was actually able to perform matrix-vector multiplication faster than numpy for very large matrices, which is very impressive. "
      ]
    }
  ]
}