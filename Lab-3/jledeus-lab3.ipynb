{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jledeus-lab3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/jledeus/jledeus_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 3: Iterative methods**\n",
        "**Johan Ledéus**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Homework 3 for DD2363 Methods in Scientific Computing\n"
      ]
    },
    {
      "metadata": {
        "id": "91u_dlHotjUW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Methods"
      ]
    },
    {
      "metadata": {
        "id": "iPcEYEuit2kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mandatory assignments"
      ]
    },
    {
      "metadata": {
        "id": "t7hPSMBgt8Me",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1. Function: Jacobi iteration for $Ax=b$\n",
        "\n",
        "####Input: matrix $A$, vector $b$\n",
        "####Output: vector $x$\n",
        "####Test: convergence of residual $|| Ax-b ||$, $|| x-y ||$ for manufactured/exact solution $y$ "
      ]
    },
    {
      "metadata": {
        "id": "zk55tQKTuSGJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution (Chapter 7 in course litterature)\n",
        "The idea with iterative methods is that we don't try to find the exact soultion for $Ax=b$ but rather the approximation.\n",
        "The matrix $A$ can be splitted into the diagonal matrix $A_1 = D$ and $A_2 = A-D$\n",
        "\n",
        "$$A = A_1 + A_2 = D + A - D = A$$\n",
        "\n",
        "Given this the jacobi iteration is defined as:\n",
        "\n",
        "$$x_i^{k+1} = a_{ii}^{-1}(b_i-\\sum_{j \\neq i}a_{ij}x_j^{(k)})$$\n",
        "\n",
        "The stopping criterion is defined as:\n",
        "$$\\frac{||r^{(k)}||}{||b||} < TOL, r^{(k)} = b-Ax^{(k)}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "o1ghMIkgy81R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def jacobi_iteration(A,b):\n",
        "  x = [1 for _ in b] # x_o = [1,1,..,1]\n",
        "  while True:\n",
        "    x_new = x\n",
        "    for i in range(len(x)):\n",
        "      x_new[i] = (1/A[i][i])*(b[i] - sum([A[i][j]*x[j] for j in range(len(A[0])) if j != i]))\n",
        "    x = x_new\n",
        "    if np.linalg.norm(b-A.dot(x))/np.linalg.norm(b) < 0.000000000001:\n",
        "      break\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49Q8U6AT5Ojw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###2. Function: Gauss-Seidel iteration for $Ax=b$\n",
        "\n",
        "####Input: matrix $A$, vector $b$\n",
        "####Output: vector $x$\n",
        "####Test: convergence of residual $|| Ax-b ||$, $|| x-y ||$ for manufactured/exact solution $y$"
      ]
    },
    {
      "metadata": {
        "id": "SLbUzjk95hqg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution\n",
        "First we split the matrix $A$ into the lower triangular matrix $L$ and the strictly upper triangular matrix $U = A - L$. With this we can construct the iterative method with:\n",
        "\n",
        "$$Ax = B \\iff (L + U)x = b \\iff x^{k+1}=L^{-1}(b - Ux^{k})  $$\n",
        "\n",
        "With the knowledge that $L$ is an lower triangular matrix we can use the forwards substitution and hence acquire:\n",
        "\n",
        "$$x_i^{(k+1)} = a_{ii}^{-1}(b - \\sum_{j<i}a_{ij}x_j^{k+1} - \\sum_{j>i}a_{ij}x_j^{(k)})$$"
      ]
    },
    {
      "metadata": {
        "id": "7G_YE_WX-QSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gauss_seidel(A,b):\n",
        "  x = [1 for _ in b] # x_o = [1,1,..,1]\n",
        "  while True:\n",
        "    x_new = x\n",
        "    for i in range(len(x)):\n",
        "      r_sum = sum([A[i][j]*x_new[j] for j in range(len(A[0])) if j < i])\n",
        "      l_sum = sum([A[i][j]*x[j] for j in range(len(A[0])) if j > i])\n",
        "      x_new[i] = (1/A[i][i])*(b[i] - l_sum - r_sum)\n",
        "    x = x_new\n",
        "    if np.linalg.norm(b-A.dot(x))/np.linalg.norm(b) < 0.000000000001:\n",
        "      break\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ApQxTrmDQOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3. Function: Newton's method for scalar nonlinear equation $f(x)=0$\n",
        "\n",
        "####Input: scalar function $f(x)$\n",
        "####Output: real number $x$\n",
        "####Test: convergence of residual $|f(x)|$, $|x-y|$ for manufactured/exact solution $y$"
      ]
    },
    {
      "metadata": {
        "id": "vg2DmQHLDiiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Solution (Algorithm 13 in course litterature)\n",
        "The purpose of Newton's method is to find roots for equations.\n",
        "\n",
        "$x^{(0)} \\in ℝ $\n",
        "\n",
        "$while |f(x^{(k)})| \\geq TOL $\n",
        "\n",
        "$ x^{(k+1)} = x^{(k)} - \\frac{f(x^{(k)})}{f'(x^{(k)})} $\n",
        "\n",
        "$end$"
      ]
    },
    {
      "metadata": {
        "id": "MfcyzXuOIfMe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def newtons_method(f, h=0.0001):\n",
        "  x = 0\n",
        "  f_prim = lambda f, x, h : (f(x+h)-f(x)) / h\n",
        "  while np.abs(f(x)) > 0.000001:\n",
        "    x = x - f(x)/f_prim(f,x, h)\n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ZrlCZULtoBu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Results"
      ]
    },
    {
      "metadata": {
        "id": "XCqBDgwP4SkZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Jacobi Iteration\n",
        "As we can see below the results for the jacobi iteration is accurate given the algorithm. Depending on the tolerance $TOL$ we might get a different result."
      ]
    },
    {
      "metadata": {
        "id": "aNY3B1T43VF9",
        "colab_type": "code",
        "outputId": "03846032-b077-4490-b360-191008557cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test for assignment 1\n",
        "A = np.array([(10,-1,2,0),(-1,11,-1,3),(2,-1,10,-1),(0,3,-1,8)])\n",
        "b = np.array([6,25,-11,15])\n",
        "x = jacobi_iteration(A,b)\n",
        "y = np.array([1, 2, -1, 1]) # Exact solution of the system\n",
        "\n",
        "assert np.linalg.norm(A.dot(x) - b) < 0.0000000001\n",
        "assert np.linalg.norm(x-y) < 0.0000000001\n",
        "print(\"Pass\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLm5KR1R_cgS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###2. Gauss-Seidel Iteration\n",
        "Similar to the previous assignment the results are promising when it comes to approximating the solution to the equation $Ax=b$"
      ]
    },
    {
      "metadata": {
        "id": "9P5lve-k_o4U",
        "colab_type": "code",
        "outputId": "5a037d3b-e33b-4690-cd74-ccdf21806297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test code for asignment 2\n",
        "A = np.array([(10,-1,2,0),(-1,11,-1,3),(2,-1,10,-1),(0,3,-1,8)])\n",
        "b = np.array([6,25,-11,15])\n",
        "x = gauss_seidel(A,b)\n",
        "y = np.array([1, 2, -1, 1]) # Exact solution of the system\n",
        "\n",
        "assert np.linalg.norm(A.dot(x) - b) < 0.0000000001\n",
        "assert np.linalg.norm(x-y) < 0.0000000001\n",
        "print(\"Pass\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dgiPSDvILF2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3. Newton's method\n",
        "The results for this metod depends on the initial guess for $x^{(0)}$ and the tolerance we use for derivation and termination criterion. Further improvements would be to include more arguments in order to generate more solutions."
      ]
    },
    {
      "metadata": {
        "id": "oGoPHIhCLQuW",
        "colab_type": "code",
        "outputId": "d87e382d-4df6-499d-c51a-a21ae22cde2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test code for assignment 3\n",
        "f = lambda x : x**2 - 1395\n",
        "x = newtons_method(f)\n",
        "assert np.abs(f(x)) < 0.000001\n",
        "assert np.abs(x - np.sqrt(1395)) < 0.000001\n",
        "\n",
        "f = lambda x : x**3 - 10*x + 2\n",
        "x = newtons_method(f,0.000001)\n",
        "\n",
        "assert np.abs(f(x)) < 0.000001\n",
        "assert np.abs(x - 0.20081) < 0.000001\n",
        "\n",
        "print(\"Pass\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TBUknfvWtsxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ]
    },
    {
      "metadata": {
        "id": "Glj-LcP37b-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The mandatory assignments was pretty straight forward but the extra which I only attempted GMRES was somewhat confusing to implement. I had some problems to implement the combination of Arnoldi with GMRES and due to lack of time I did not finish any extra assignments. As mentioned in lecture I think it's interesting to discuss the abilities when it comes to parallelism and dependencies of data."
      ]
    }
  ]
}