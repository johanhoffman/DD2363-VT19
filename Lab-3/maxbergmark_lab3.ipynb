{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maxbergmark_lab3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/maxbergmark/Lab-3/maxbergmark_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 3: Iterative methods**\n",
        "**Max Bergmark**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This lab is about implementing iterative methods to solve matrix equations and find zeros of functions. "
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**About the code**"
      ]
    },
    {
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I am the author of the code in its entirety."
      ]
    },
    {
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Methods**"
      ]
    },
    {
      "metadata": {
        "id": "bfzj-1KwTyX3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "\n",
        "To improve readability of the code, I implemented these two helper functions."
      ]
    },
    {
      "metadata": {
        "id": "dxG8aZltT9ZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# return a normalized version of a vector\n",
        "def normalize(v):\n",
        "    return v / np.linalg.norm(v)\n",
        "  \n",
        "# return the length of a vector\n",
        "def norm(v):\n",
        "    return np.linalg.norm(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zF4iBj5VURZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Jacobi iteration for $Ax=b$\n",
        "\n",
        "The idea behind Jacobi iteration is to split the matrix A into a diagonal matrix and a residual. Since it is easy to find the inverse of a diagonal matrix, the iteration step becomes trivial. Once the inverse is found, we iterate 1000 times and then return the found vector $x$. For matrix equations with exact solutions, you could add a breaking condition. However, if the system is not exactly solvable, it is more difficult to find a stopping criterion."
      ]
    },
    {
      "metadata": {
        "id": "Kn3b4nDNOVKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jacobi_iterate(A, b):\n",
        "    D = np.diag(np.diag(A))\n",
        "    R = A - D\n",
        "    D_inv = np.diag(1/np.diag(D))\n",
        "    x = np.ones(A.shape[1])\n",
        "    for _ in range(1000):\n",
        "        x = np.dot(D_inv, b - np.dot(R, x))\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jd3Ks5H-OnvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Gauss-Seidel iteration for $Ax=b$\n",
        "\n",
        "The Gauss-Seidel iteration is also based around splitting the matrix $A$ into two parts, but this time it is a lower triangular part, and the residual. The inverse of a triangular matrix is relatively easy to find, which makes this algorithm easy to implement. "
      ]
    },
    {
      "metadata": {
        "id": "M5nMlIlXO15k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gauss_seidel(A, b):\n",
        "    x = np.zeros(A.shape[1])\n",
        "    for _ in range(1000):\n",
        "        x_new = x.copy()\n",
        "        for i in range(x.size):\n",
        "            L_sum = np.dot(A[i,:i], x_new[:i])\n",
        "            U_sum = np.dot(A[i,i+1:], x[i+1:])\n",
        "            x_new[i] = 1/A[i,i]*(b[i] - L_sum - U_sum)\n",
        "            x = x_new\n",
        "    return x_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrG1MdSLQVWZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Newton's method for scalar nonlinear equation $f(x)=0$\n",
        "\n",
        "Newton's method for finding zeros of functions. Geometrically, it works by starting at any function point, and drawing a tangent along the function and checking where that tangent intersects the x axis. The x-value for the intersection point becomes your new guess.\n",
        "\n",
        "To implement this algorithm, you must be able to calculate the derivative of the function at certain points. This can be done by using central difference, which has better convergence than the regular formula for function derivatives. "
      ]
    },
    {
      "metadata": {
        "id": "MPgn3vd_Rkmk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def df(f, x, h):\n",
        "    return (f(x+h) - f(x-h)) / (2*h)\n",
        "\n",
        "def newton(f, x):\n",
        "    iters = 0\n",
        "    fx = f(x)\n",
        "    while np.max(abs(fx)) > 1e-15:\n",
        "        fx = f(x)\n",
        "        x -= fx / df(f, x, 1e-8)\n",
        "        iters += 1\n",
        "        if iters > 100000:\n",
        "            print(f(x))\n",
        "            raise ValueError(\"No solution found\")\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzKmxchwRopv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4: GMRES method for $Ax=b$\n",
        "\n",
        "The Generalized Minimal Residuals method is another method for solving matrix equations. It is more complicated, and since the algorithm itself also includes solving a least-squares problem, it feels superfluous. \n",
        "\n",
        "It works by applying successive Arnoldi iterations, and then minimizing the residual. "
      ]
    },
    {
      "metadata": {
        "id": "PMP-mJDITWB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def arnoldi(A, b, k, Q, H, k_max):\n",
        "    v = np.dot(A, Q[:,k])\n",
        "    for j in range(k):\n",
        "        H[j,k] = np.dot(Q[:,j], v)\n",
        "        v -= H[j,k]*Q[:,j]\n",
        "    H[k+1,k] = norm(v)\n",
        "    if (H[k+1, k] != 0 and k != k_max -1):\n",
        "        Q[:,k+1] = v / H[k+1,k]\n",
        "\n",
        "def gmres(A, b):\n",
        "    k_max = 100\n",
        "    n = A.shape[0]\n",
        "    x0 = np.zeros(n)\n",
        "\n",
        "    x = np.zeros(n)\n",
        "    r = b - np.dot(A, x0)\n",
        "\n",
        "    Q = np.zeros((n, k_max))\n",
        "    H = np.zeros((k_max+1, k_max))\n",
        "    Q[:,0] = normalize(r)\n",
        "\n",
        "    for k in range(k_max):\n",
        "        arnoldi(A, b, k, Q, H, k_max)\n",
        "\n",
        "        b = np.zeros(k_max+1)\n",
        "        b[0] = norm(r)\n",
        "\n",
        "        res = np.linalg.lstsq(H, b, rcond = None)[0]\n",
        "        x = np.dot(Q, res) + x0\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtXX7LZC_joO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5: Newton's method for vector nonlinear equation $f(x)=0$\n",
        "\n",
        "This task uses the exact same code as the one for task 3, since I implemented it to handle scalars implicitly while handling numpy arrays. In higher dimensions, the gradient is the analog to the derivative. It is computed in the exact same way for each dimension as the 1-dimensional case. "
      ]
    },
    {
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ]
    },
    {
      "metadata": {
        "id": "RLwlnOzuV-Cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1: Jacobi iteration for $Ax=b$"
      ]
    },
    {
      "metadata": {
        "id": "bHkaEA50Ti0-",
        "colab_type": "code",
        "outputId": "ed34c6c1-2289-4f32-be53-428b3198baa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_jacobi_iteration():\n",
        "    A = np.array([[2, 1], [5, 7]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([7+1/9, -3-2/9])\n",
        "    x = jacobi_iterate(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    A = np.array(\n",
        "        [\n",
        "            [10, -1, 2, 0], \n",
        "            [-1, 11, -1, 3], \n",
        "            [2, -1, 10, -1], \n",
        "            [0, 3, -1, 8]\n",
        "        ], dtype = np.float64\n",
        "    )\n",
        "    b = np.array([6, 25, -11, 15])\n",
        "    x_true = np.array([1, 2, -1, 1])\n",
        "    x = jacobi_iterate(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "\n",
        "test_jacobi_iteration()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C0Lvb1bbUJHI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2: Gauss-Seidel iteration for $Ax=b$\n"
      ]
    },
    {
      "metadata": {
        "id": "IdOnfvQ9UJ4X",
        "colab_type": "code",
        "outputId": "458d7ba5-adb9-4222-e3f6-6a63b78cfc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_gauss_seidel():\n",
        "    A = np.array([[16, 3], [7, -11]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([0.81218274, -0.66497462])\n",
        "    x = gauss_seidel(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    A = np.array([[2, 1], [5, 7]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([7+1/9, -3-2/9])\n",
        "    x = gauss_seidel(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    \n",
        "test_gauss_seidel()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fMoW-M8OUSu4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3: Newton's method for scalar nonlinear equation $f(x)=0$\n",
        "\n",
        "Here, we test 100 random polynomials of degree 2. Since we can determine the exact solutions, we are able to compare the found value to the exact values, and verify that it converges to either one of them. "
      ]
    },
    {
      "metadata": {
        "id": "jeIy_nqQUTvq",
        "colab_type": "code",
        "outputId": "c8b96517-fa75-4d25-e277-405856e56257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_polynomial():\n",
        "    for _ in range(100):\n",
        "        p = np.random.randn()\n",
        "        q = np.random.randn()\n",
        "        f = lambda x: x**2 + p*x + q\n",
        "        if q < p*p/4:\n",
        "            x_0 = -p/2 + (p*p/4 - q)**.5\n",
        "            x_1 = -p/2 - (p*p/4 - q)**.5\n",
        "            x_start = 0\n",
        "            x = newton(f, x_start)\n",
        "            assert np.isclose(x, x_0) or np.isclose(x, x_1)\n",
        "            \n",
        "test_polynomial()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWVDmlyvUcCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4: GMRES method for $Ax=b$"
      ]
    },
    {
      "metadata": {
        "id": "-NWG2QG_Uc9G",
        "colab_type": "code",
        "outputId": "aeca6de4-769f-4b61-b810-2e8b382a4e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test_GMRES():\n",
        "    A = np.array([[2, 1], [5, 7]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([7+1/9, -3-2/9])\n",
        "    # x = GMRes(A, b, np.zeros(A.shape[1]), 0, 5)\n",
        "    # print(x)\n",
        "    x = gmres(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    A = np.array([[16, 3], [7, -11]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([0.81218274, -0.66497462])\n",
        "    x = gmres(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    A = np.array([[2, 1], [5, 7]], dtype = np.float64)\n",
        "    b = np.array([11, 13])\n",
        "    x_true = np.array([7+1/9, -3-2/9])\n",
        "    x = gmres(A, b)\n",
        "    assert np.allclose(x, x_true)\n",
        "    \n",
        "test_GMRES()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2qzngjm8GQgd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5: Newton's method for vector nonlinear equation $f(x)=0$\n",
        "\n",
        "Here, we test the vector function $(x-1)^2$, which has the solution $x_i = 1$. We also test the function $g(x)$, which is designed to have the solution $x_i = i$. We test them for different number dimensions between 1 and 10."
      ]
    },
    {
      "metadata": {
        "id": "CclvcE51GT0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "663ab2e4-3c92-4712-d50e-369dc7b8d9cf"
      },
      "cell_type": "code",
      "source": [
        "def test_vector_polynomial():\n",
        "    f = lambda x: (x - 1)**2 \n",
        "    g = lambda x: (x- np.arange(x.size))**3\n",
        "    for n in range(1, 10):\n",
        "        x = np.zeros(n)\n",
        "        x = newton(f, x)\n",
        "        assert np.allclose(x, 1)\n",
        "        x = np.zeros(n)\n",
        "        x = newton(g, x)        \n",
        "        assert np.allclose(x, np.arange(x.size))\n",
        "\n",
        "test_vector_polynomial()\n",
        "print(\"Test passed!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f7t9JNIdU_tT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Full test suite\n",
        "\n",
        "Use this to run all tests at once."
      ]
    },
    {
      "metadata": {
        "id": "hayrpMn7VHMJ",
        "colab_type": "code",
        "outputId": "d44af524-dae4-4f7f-cc48-b75ae8966516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def run_test_suite():\n",
        "    test_jacobi_iteration()\n",
        "    test_gauss_seidel()\n",
        "    test_polynomial()\n",
        "    test_GMRES()\n",
        "    test_vector_polynomial()\n",
        "\n",
        "run_test_suite()\n",
        "print(\"All tests passed!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All of the algorithms were fairly straight-forward to implement given the instructions in the lecture notes. However, the GMRES algorithm wouldn't converge properly when I used the least squares solver from Lab 2, so I used the one from numpy instead. "
      ]
    }
  ]
}