{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-report-lab-X.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT19/blob/tobzed/Lab-3/tedwards_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Lab 3: Iterative Methods**\n",
        "**Tobias Edwards**"
      ]
    },
    {
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "metadata": {
        "id": "6UFTSzW7P8kL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This lab focused on iterative methods for solving linear equation systems of the form $Ax = b$. These methods included:\n",
        "Jacobi iteration, Gauss-Seidel iteration and the Generalized minimal residual method. This lab also looked at solving nonlinear equations and nonlinear systems of equation such that a continuous function $f(x) = 0$. "
      ]
    },
    {
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**About the code**"
      ]
    },
    {
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following code is authored by Tobias Edwards for the third lab in course DD2363  Methods in Scientific Computing.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np\n",
        "import unittest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Jacobi method and the Gauss-Sediel method require that the matrix $A$ is diagonally dominant for the methods to converge. Informally, this means that each element on the diagonal has a magnitude at least as large as the sum of the magnitudes of the other elements on the corresponding row. These methods are called \"fixed-point iterative\" as they find a solution $x^{(k+1)}$ by applying the same algorithm on the previous approximation $x^{(k)}$. The generalized minimal residual (gmres) method works by creating an orthonormal Krylov basis and then solving a least squares problem.Newton's method for scalar equations functions by finding the dervivative of a point, creating a line from that derivative, and finding where this line intersects the x-axis. This point of intersection will be our new approximation. The method for solvning nonlinear systems is a generalization of Newton's method for scalar equations where the derivative is replaced by the jacobian matrix.  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ]
    },
    {
      "metadata": {
        "id": "ChMfNEPY7Vtd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Jacobi method"
      ]
    },
    {
      "metadata": {
        "id": "g8R9EXRi9Neb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This method solves $Ax = b$ by the iteration $x^{(k+1)} = (I-A)x^{(k)} + b$, a form of Richardson's iteration such that $M = I - A$. In this algorithm we split $A = A_1 + A_2$such that $A_1$is a diagonal matrix and $A_2$ is equal to $A-D$. $A_1$ is now easy to invert. "
      ]
    },
    {
      "metadata": {
        "id": "f7H0a1Hg7eBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jacobi_iteration(A,b,TOL):\n",
        "    n  = A.shape[0]\n",
        "    x = np.zeros(n)\n",
        "    r_norm = np.linalg.norm(b-A.dot(x))\n",
        "    while r_norm >= TOL:\n",
        "        x_old = np.copy(x)\n",
        "        for i in range(n):\n",
        "            val = 0.0\n",
        "            for j in range(n):\n",
        "                if j != i:\n",
        "                    val = val + A[i,j]*x_old[j]\n",
        "            x[i] = (b[i]-val)/A[i,i]\n",
        "        r_norm = np.linalg.norm(b-A.dot(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFxem-0C7hoG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gauss-Seidel method"
      ]
    },
    {
      "metadata": {
        "id": "hDqOmFs6-k3x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This method instead splits $A$ into two triangular matrices which can be inverted my forward/backward substitution. "
      ]
    },
    {
      "metadata": {
        "id": "vcA9RQgx7l3M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gauss_seidel_iteration(A,b,TOL):\n",
        "    x = np.zeros(A.shape[0])\n",
        "    n,m = A.shape\n",
        "    r_norm = np.linalg.norm(b-A.dot(x))\n",
        "    while r_norm >= TOL:\n",
        "        x_next = np.zeros_like(x)\n",
        "        for i in range(n):\n",
        "            val = b[i]\n",
        "            for j in range(n):\n",
        "                if j < i:\n",
        "                    val -= A[i,j]*x_next[j]\n",
        "                if j > i:\n",
        "                    val -= A[i,j]*x[j]\n",
        "            x_next[i] = np.float(val/A[i,i])\n",
        "        x = x_next.copy()\n",
        "        r_norm = np.linalg.norm(b-A.dot(x_next))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3E5x1Tu7owv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Newton's method for scalar nonlinear equation"
      ]
    },
    {
      "metadata": {
        "id": "qXU5MTff7wbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def newtons_method(f,df,TOL,x=None):\n",
        "    if x == None:\n",
        "        x = np.random.rand()\n",
        "    iteration = 0\n",
        "    while np.linalg.norm(f(x)) >= TOL and iteration < 500:\n",
        "        x -= f(x)/df(x)\n",
        "    if iteration == 500:\n",
        "        return None\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ei9i_PtB7zKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GMRES "
      ]
    },
    {
      "metadata": {
        "id": "JYN81oWdC8hN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The arnoldi method is used to create an orthonormal basis consisting of $k$ vectors $<b, Ab, A^2b...A^{k-1}b>$, and also creates an upper Hessenberg matrix. The Hessenberg matrix is used to solve a least squares problem and then the $k+1$ iteration of $x$ is given by $Qy$ where $y$ is the solution to the least squares problem. "
      ]
    },
    {
      "metadata": {
        "id": "blii0tMY73me",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def arnoldi_iteration(A,b,k):\n",
        "    Q = np.zeros((A.shape[0],k+1))\n",
        "    H = np.zeros((k+1,k))\n",
        "    Q[:,0] = b/np.linalg.norm(b)\n",
        "    for i in range(k):\n",
        "        v = A.dot(Q[:,i])\n",
        "        for j in range(i+1):\n",
        "            H[j,i] = np.inner(Q[:,j],v)\n",
        "            v -= H[j,i]*Q[:,j]\n",
        "        H[i+1,i] = np.linalg.norm(v)\n",
        "        Q[:,i+1] = v / H[i+1,i]\n",
        "    return Q,H\n",
        "\n",
        "def gmres(A,b,TOL):\n",
        "    x = np.zeros(A.shape[0])\n",
        "    b_norm = np.linalg.norm(b)\n",
        "    k = 1\n",
        "    while np.linalg.norm(b-A.dot(x)) >= TOL:\n",
        "        Q,H = arnoldi_iteration(A,b,k) # this gives us Q_{k+1} and correspinding upper Hessenberg\n",
        "        e1 = np.zeros(k+1)\n",
        "        e1[0] = 1\n",
        "        y = np.linalg.lstsq(H,b_norm*e1,rcond=-1)[0]\n",
        "        x = Q[:,:k].dot(y)\n",
        "        k = k + 1\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUhF_-mF8jPI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Newton's method for vector nonlinear equation"
      ]
    },
    {
      "metadata": {
        "id": "pfAv3jJB8nnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def newtons_systems(f, jacobian, dim, TOL):\n",
        "    x = np.random.rand(dim)\n",
        "    while np.linalg.norm(f(x)) >= TOL:\n",
        "        grad = gmres(jacobian(x),-f(x),TOL)\n",
        "        x += grad\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vwbz_EXZ8v2R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ]
    },
    {
      "metadata": {
        "id": "63TLvt808y51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "6fbdf3aa-5354-4f6c-dfbc-e19b897a513e"
      },
      "cell_type": "code",
      "source": [
        "class Lab3FunctionsTest(unittest.TestCase):\n",
        "\n",
        "    def test_jacobi_iteration(self):\n",
        "        TOL_list = [1, 1e-2, 1e-4, 1e-7]\n",
        "        A = np.array([ # diagonally dominat matrix\n",
        "                    [10.,1.,-2.,3.],\n",
        "                    [-1.,15.,4.,1.],\n",
        "                    [0.,0.,4.,-1.],\n",
        "                    [10.,-7.,2.,80.]\n",
        "                    ])\n",
        "        b = np.array([0.,4.,-2.,1.])\n",
        "        for TOL in TOL_list:\n",
        "            x = jacobi_iteration(A,b,TOL)\n",
        "            self.assertTrue(np.linalg.norm(A.dot(x)-b) < TOL)\n",
        "        A2 = np.array([[3,0,-1], [0,-2,1], [0,0,6]])\n",
        "        b2 = np.array([4,0,1])\n",
        "        y = np.array([25./18., 1./12., 1./6.]) # exact solution\n",
        "        x2 = jacobi_iteration(A2,b2,TOL_list[3])\n",
        "        self.assertTrue(np.linalg.norm(x2-y) < TOL_list[3])\n",
        "\n",
        "    def test_gauss_seidel_iteration(self):\n",
        "        TOL_list = [1, 1e-2, 1e-4, 1e-7]\n",
        "        A = np.array([ # diagonally dominant matrix\n",
        "                    [10.,1.,-2.,3.],\n",
        "                    [-1.,15.,4.,1.],\n",
        "                    [0.,0.,4.,-1.],\n",
        "                    [10.,-7.,2.,80.]\n",
        "                    ])\n",
        "        b = np.array([0.,4.,-2.,1.])\n",
        "        for TOL in TOL_list:\n",
        "            x = gauss_seidel_iteration(A,b,TOL)\n",
        "            self.assertTrue(np.linalg.norm(A.dot(x)-b) < TOL)\n",
        "        A2 = np.array([[3,0,-1], [0,-2,1], [0,0,6]])\n",
        "        b2 = np.array([4,0,1])\n",
        "        y = np.array([25./18., 1./12., 1./6.]) # exact solution\n",
        "        x2 = gauss_seidel_iteration(A2,b2,TOL_list[3])\n",
        "        self.assertTrue(np.linalg.norm(x2-y) < TOL_list[3])\n",
        "\n",
        "    def test_newtons_method(self):\n",
        "        f = lambda x: x**3 - 2*x - 4\n",
        "        df = lambda x: 3*x**2 - 2\n",
        "        TOL_list = [1, 1e-2, 1e-4, 1e-7]\n",
        "        for TOL in TOL_list:\n",
        "            x = newtons_method(f,df,TOL)\n",
        "            self.assertTrue(f(x) < TOL)\n",
        "            self.assertTrue(np.linalg.norm(f(x)-f(2.)) < TOL)\n",
        "            \n",
        "    def test_gmres(self):\n",
        "        A = np.array([[1,0,-2,4],[-1,2,5,3], [-7,8,2,9], [0,8,2,-1]])\n",
        "        b = np.array([1,-2,5,3])\n",
        "        TOL_list = [1, 1e-2, 1e-4, 1e-7]\n",
        "        for TOL in TOL_list:\n",
        "            x = gmres(A,b,TOL)\n",
        "            self.assertTrue(np.linalg.norm(b-A.dot(x)) < TOL)\n",
        "        A2 = np.array([[-2,3],[8,2]])\n",
        "        b2 = np.array([1,-1])\n",
        "        y = np.array([-10./56., 3./14.])\n",
        "        for TOL in TOL_list:\n",
        "            x2 = gmres(A2,b2,TOL)\n",
        "            self.assertTrue(np.linalg.norm(y-x2) < TOL)\n",
        "\n",
        "    def test_newtons_systems(self):\n",
        "        f = lambda x: np.array([\n",
        "                                (x[0]**2)*x[1] + 3*x[2] - x[1]**3 + 1,\n",
        "                                3*x[1]-x[2]**2+x[0],\n",
        "                                x[0]**3-7*x[1]+x[2]\n",
        "                              ])\n",
        "        df = lambda x: np.array([\n",
        "                            [ 2*x[0]*x[1], x[0]**2-3*x[1]**2, 3 ],\n",
        "                            [ 1, 3, -2*x[2] ],\n",
        "                            [3*x[0]**2, -7, 1 ]\n",
        "                            ])\n",
        "        TOL_list = [1, 1e-2, 1e-4, 1e-7]\n",
        "        for TOL in TOL_list:\n",
        "            x = newtons_systems(f,df,3,TOL)\n",
        "            self.assertTrue(np.linalg.norm(f(x)) < TOL)\n",
        "        \n",
        "        f2 = lambda x: np.array([x[0]-3,x[1]+2,x[2]])\n",
        "        df2 = lambda x: np.array([[1,0,0], [0,1,0], [0,0,1]])\n",
        "        y = np.array([3,-2,0]) # exact solution\n",
        "        for TOL in TOL_list:\n",
        "            x2 = newtons_systems(f2,df2,3,TOL)\n",
        "            self.assertTrue(np.linalg.norm(x2-y) < TOL)\n",
        "            \n",
        "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..../usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.027s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fa584d66b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "ZgQmho1f8qRU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ]
    },
    {
      "metadata": {
        "id": "cC7E2P3IDowo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The theory for this lab was easier to understand than last weeks theory. However, I found this weeks programming to be quite challenging. Also, I had to make sure that the arguments would result in convergence for some algorithms; something that I forgot and spent a long time trying to figure out why my algorithms were not working. "
      ]
    }
  ]
}